{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2172481e",
   "metadata": {},
   "source": [
    "Execute the following steps by first creating a word embedding for the documents in the folder GOT. The following parameters should be used:\n",
    "Features: 200 // Context Window Size: 5 //Epochs: 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab95aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "import os\n",
    "\n",
    "documents = []\n",
    "\n",
    "# Loop over each got*.txt file\n",
    "for i in range(1, 6): \n",
    "    filepath = os.path.join('GOT', 'Data', f'got{i}.txt')\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        doc = f.read()\n",
    "        # Tokenize the document\n",
    "        documents.append(simple_preprocess(doc))\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = Word2Vec(sentences=documents, vector_size=200, window=5, epochs=80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fffe8fe",
   "metadata": {},
   "source": [
    "\n",
    "1. Print the vector for Arryn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833a8b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.16910532 -0.20335367 -0.28906646 -1.7058661   0.0926455  -0.56090885\n",
      "  1.1572804   0.04394329 -0.3325822   0.21066473 -0.03158003  0.1615453\n",
      " -0.5308565   0.8657827  -0.7790069   0.09697251  0.7075956   0.2315436\n",
      "  0.1529803   0.33327636  2.1544974  -0.65217435 -0.1287352   0.05677405\n",
      "  0.39078915 -0.66265047  0.10477664 -1.0986859   0.438428    0.13987453\n",
      "  1.169158    0.6529507   0.355075   -0.49113747 -0.25107735  0.09587108\n",
      " -0.78884244 -0.6449325  -0.03348136 -1.4790632  -0.1292628   0.17506275\n",
      "  0.27153802  0.717806   -0.5283684  -0.14811437 -1.2741312  -0.49333453\n",
      "  0.58669436 -0.30393827  0.06895871 -0.8859195   0.7393487  -0.02703416\n",
      "  0.07199813 -1.1526808   0.0589879   0.81710887 -1.081468   -0.37246004\n",
      " -0.50942284 -1.0897434   0.2420534  -0.67245066  0.4905369  -0.38591692\n",
      "  0.46718907  0.2112353  -0.1958357  -0.34739408 -0.53284305 -0.03657525\n",
      " -0.58850324 -0.39419562  0.06923894  0.02035049 -0.5239414   0.26584294\n",
      " -0.91015166  0.33897796 -0.20762885  0.45632896  0.15031217  0.77640903\n",
      " -0.61356694 -0.01040131 -0.5702423   0.4616709  -0.72265023 -0.12064944\n",
      " -0.12478855  0.60649693 -0.12653428 -0.74372107  0.14879467 -0.7074287\n",
      " -1.0483795   0.01232256  0.44192952  0.15127969 -0.4744223  -0.08023007\n",
      " -0.50745916  0.20555757 -0.1990287  -0.4357937  -0.42064816  0.5087629\n",
      " -1.5387148  -0.577295   -0.4270977  -0.80510765  0.01655049  0.02512981\n",
      "  0.42519686  0.3038737  -0.11294412  0.18208459  0.2645695   0.15579641\n",
      "  0.07070817  0.13733669 -0.3378466  -0.0544669   0.3305523   0.9104013\n",
      " -0.0384365  -0.09839875 -0.01898092 -0.43400574 -0.52778924  0.2901637\n",
      " -0.02154727 -0.42989105  0.0394907  -1.3058093   0.2601152  -0.06503743\n",
      " -0.31407368  0.3747421   0.37235993  0.2324147  -0.685833    0.46401817\n",
      "  0.05419413  0.24071586 -0.5293023   0.60383785  0.7364553  -0.32099766\n",
      " -0.06941875 -0.2617384  -0.72990483  0.6853032  -0.5186908   0.45845482\n",
      "  0.18213415 -0.09311638  0.02288627 -0.29988143 -0.15856336  0.18087558\n",
      "  0.22664155  0.56561315  0.22714175  0.5323526  -0.2968098  -0.51581407\n",
      " -0.7406313  -0.23004234  0.7015195   0.18165547 -1.0529443   0.49876794\n",
      " -0.5212401   0.01744945  0.2747363   0.19291668  0.40102375  0.54434204\n",
      " -0.4293894  -0.70207024 -0.43049002  1.2213453  -0.20294793  0.21010228\n",
      "  0.9286999   0.34745878  0.4214072   0.35569146  0.2324425   0.94286937\n",
      " -0.77424145 -0.41079572  0.5387858   1.3539186   0.44318438 -0.9494857\n",
      "  0.55407715 -0.04572187]\n"
     ]
    }
   ],
   "source": [
    "if \"arryn\" in model.wv:\n",
    "    print(model.wv['arryn'])\n",
    "else:\n",
    "    print(\"Word 'Arryn' not found in vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3971f56f",
   "metadata": {},
   "source": [
    "2. How many vectors are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe3f5dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique vectors (words): 11766\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of unique vectors (words): {len(model.wv)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddec592",
   "metadata": {},
   "source": [
    "\n",
    "3. Which 7 words are the most similar to “Lannister”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "520ea1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beardless', 'cersei', 'aboard', 'rhaegar', 'stark', 'especially', 'grell']\n"
     ]
    }
   ],
   "source": [
    "similar_words = model.wv.most_similar(\"lannister\", topn=7)\n",
    "print([word[0] for word in similar_words])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3b4894",
   "metadata": {},
   "source": [
    "4. How similar are “Jon” and “Ygritte”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745ff85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score between 'Jon' and 'Ygritte': 0.05349407345056534\n"
     ]
    }
   ],
   "source": [
    "similarity_score = model.wv.similarity(\"jon\", \"ygritte\")\n",
    "print(f\"Similarity score between 'Jon' and 'Ygritte': {similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65e99d7",
   "metadata": {},
   "source": [
    "How similar are the two sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b28b843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score between the two sentences: 0.030458485707640648\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "sentence1_vector = get_sentence_vector(\"Hodor that was all he ever said\", model)\n",
    "sentence2_vector = get_sentence_vector(\"Hold the door\", model)\n",
    "\n",
    "similarity_between_sentences = cosine_similarity(sentence1_vector, sentence2_vector)\n",
    "print(f\"Similarity score between the two sentences: {similarity_between_sentences}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f38f0f2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
